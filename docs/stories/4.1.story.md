# Story 4.1 — Nautilus adapter integration (BacktestRunnerPort)
Story ID: S4.1
Epic ID: E4



Status: Draft

User Story
- As a developer,
- I want a Nautilus-based BacktestRunnerPort implementation that can execute a baseline SMA crossover on 1m bars,
- So that the backend can run strategies against derived Parquet inputs and later persist artifacts.

Context
- First story of Epic 4. Focus on adapter boundary and successful execution against bars — artifact persistence handled next.

Acceptance Criteria
1) Implement `adapters/nautilus.py` providing `BacktestRunnerPort.run(...)` per Source Tree ports
2) Given dataset_id with Parquet bars, adapter runs a minimal SMA(20/50) crossover and produces in-memory results (orders/fills/equity/metrics)
3) Logs include start/end, run_id, duration; no event-loop blocking; callable from a subprocess
4) Adapter isolates Nautilus-specific details behind the port; no leakage into services
5) Lint passes; code compiles; a smoke test function can be invoked manually (e.g., via a tiny script or REPL)

Dev Notes (sourced from architecture docs)
- Ports/Adapters: `BacktestRunnerPort` boundary; adapters/nautilus.py is the impl [Source: architecture.md#source-tree-and-module-boundaries]
- Data Models: Run + artifacts structures, minimal required fields [Source: architecture.md#data-models]
- Tech Stack: Nautilus Trader 0.10.x; Parquet inputs; Polars/PyArrow for IO [Source: architecture.md#tech-stack]
- NFRs: No CPU-bound work in request path; run from Typer or background [Source: architecture.md#non-functional-requirements-and-performance-budgets]

Technical Specifications
- Input: dataset_id → resolve bars_1m.parquet path(s) (service will pass); symbol/time-range implied by dataset
- Strategy: baseline SMA crossover (fast=20, slow=50); seed used where applicable
- Output (in-memory for this story):
  - orders: [{ts_utc, side, qty, price, order_id, type, time_in_force}]
  - fills: [{ts_utc, order_id, qty, price, fill_id, slippage, fee}]
  - equity: time series [{ts_utc, value}]
  - metrics: minimal set {total_return, max_drawdown}
- Adapter returns a structured result object; next story will persist to FS and catalog

Tasks / Subtasks
- Define `BacktestRunnerPort` interface in backend/ports/backtest_runner.py (if not already)
- Implement `adapters/nautilus.py`:
  - Load bars from Parquet; map to Nautilus feed format
  - Configure and run strategy; collect orders/fills/equity; compute minimal metrics
  - Return result object; ensure deterministic behavior (seed)
- Add thin wrapper callable from CLI to smoke test (temporary script ok)
- `make lint` backend/

Testing & Validation
- Prepare a tiny sample Parquet (or use derived slice) and run adapter in isolation
- Validate non-empty orders/fills/equity for the sample; verify logs show duration

Definition of Done
- Adapter runs a baseline backtest from Parquet bars and returns structured results via the defined port; no API blocking; code organized per Source Tree.

