# Story 8.4: Run Data Aggregation Endpoint

**Epic**: Epic 8 â€” Backend-for-Frontend (BFF) Implementation
**Priority**: High
**Effort**: 3-4 days
**Dependencies**: Story 8.2 (Basic HTTP Proxy Implementation)
**Status**: Ready for Development

## User Story

As a **trader**,  
I want **complete backtest information in a single request**,  
So that **I can quickly review run performance without multiple loading states and complex data coordination**.

## Story Context

### Existing System Integration

- **Integrates with**: Existing backend endpoints (`/backtests/{id}`, `/backtests/{id}/metrics`, `/backtests/{id}/equity`)
- **Technology**: FastAPI async patterns, Pydantic data models, concurrent request handling
- **Follows pattern**: Existing backend data aggregation and response formatting
- **Touch points**: Frontend run detail components, backend run APIs, performance metrics display

### Business Context

This story eliminates the complexity of coordinating multiple API calls for run details by providing a single aggregated endpoint. This reduces frontend loading states, improves user experience, and centralizes run data logic in the BFF layer.

## Acceptance Criteria

### Functional Requirements

1. **Aggregated Run Endpoint**
   - New endpoint `/api/v1/runs/{id}/complete` combines multiple backend calls
   - Single request replaces separate calls to run details, metrics, and equity endpoints
   - Optional parameters control which data components to include
   - Consistent response format with all run information

2. **Data Aggregation Logic**
   - Concurrent backend calls for run details, metrics, equity, and orders
   - Intelligent error handling for partial data failures
   - Data transformation to frontend-optimized format
   - Metadata about data sources and load times

3. **Flexible Data Inclusion**
   - `include_orders` parameter controls order data inclusion (default: true)
   - `include_equity` parameter controls equity curve inclusion (default: true)
   - `include_metrics` parameter controls metrics inclusion (default: true)
   - Partial responses when some data unavailable

4. **Response Optimization**
   - Aggregated response with run, metrics, equity, and orders sections
   - Metadata includes load times, cache status, and data source information
   - Error handling preserves partial data when possible
   - Consistent data formats across all included sections

### Integration Requirements

5. **Backend Compatibility**
   - Existing backend run endpoints continue to work unchanged
   - No modifications to backend data formats or API contracts
   - BFF handles all backend communication and aggregation logic
   - Backend authentication and authorization preserved

6. **Frontend Integration**
   - Response format designed for direct consumption by run detail components
   - Existing frontend data coordination logic can be removed
   - Compatible with existing run visualization and analysis patterns
   - Error responses provide clear information about data availability

7. **Performance Requirements**
   - Complete run data loads within 1 second for cached runs
   - Concurrent backend calls minimize total response time
   - Intelligent caching for frequently accessed runs
   - Graceful handling of large equity curves and order histories

### Quality Requirements

8. **Caching Strategy**
   - Redis caching for complete run data aggregations
   - Cache keys based on run ID and included data components
   - TTL-based expiration (1 minute for active runs, longer for completed)
   - Cache invalidation when run data updates

9. **Error Handling**
   - Graceful degradation when individual data sources fail
   - Partial responses with clear indication of missing data
   - Retry logic for transient backend failures
   - Consistent error format for frontend handling

10. **Concurrent Processing**
    - Async concurrent calls to multiple backend endpoints
    - Timeout handling for slow backend responses
    - Circuit breaker pattern for backend reliability
    - Request correlation across multiple backend calls

## Technical Notes

### Data Aggregation Pattern
```python
# Example aggregation logic
async def get_complete_run_data(
    run_id: str,
    include_orders: bool = True,
    include_equity: bool = True,
    include_metrics: bool = True
) -> CompleteRunResponse:
    # Concurrent backend calls
    tasks = [
        backend_client.get_run_details(run_id),
    ]
    
    if include_metrics:
        tasks.append(backend_client.get_run_metrics(run_id))
    if include_equity:
        tasks.append(backend_client.get_run_equity(run_id))
    if include_orders:
        tasks.append(backend_client.get_run_orders(run_id))
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Process results and handle partial failures
    return aggregate_run_data(results, include_flags)
```

### Response Format
```python
class CompleteRunResponse(BaseModel):
    run: RunDetail
    metrics: Optional[RunMetrics] = None
    equity: Optional[List[EquityPoint]] = None
    orders: Optional[List[OrderData]] = None
    metadata: ResponseMetadata
```

### Caching Strategy
- Cache key format: `run_complete:{run_id}:{include_flags_hash}`
- TTL based on run status: 1min for running, 5min for recent, 1hr for completed
- Partial cache invalidation when specific data updates
- Cache warming for popular runs

### Error Handling Strategy
- Continue aggregation even if some data sources fail
- Include error information in metadata for debugging
- Provide partial responses with clear data availability indicators
- Implement retry logic with exponential backoff

## Definition of Done

- [ ] **Aggregated Endpoint**: `/api/v1/runs/{id}/complete` successfully combines multiple backend calls
- [ ] **Concurrent Processing**: Backend calls executed concurrently to minimize response time
- [ ] **Flexible Inclusion**: Optional parameters control which data components are included
- [ ] **Caching**: Redis caching implemented with appropriate TTL and invalidation strategies
- [ ] **Error Handling**: Graceful degradation provides partial responses when possible
- [ ] **Performance**: Complete run data loads within performance targets
- [ ] **Testing**: Comprehensive tests cover aggregation, caching, and error scenarios
- [ ] **Documentation**: API documentation and frontend integration guide created

## Risk Assessment

### Primary Risk
**Data Inconsistency**: Aggregated data from different timestamps creates inconsistent view

### Mitigation
- Timestamp validation across data sources
- Metadata includes data freshness information
- Clear documentation of data consistency expectations

### Secondary Risk
**Partial Failure Complexity**: Handling partial data failures increases complexity

### Mitigation
- Clear error handling patterns and documentation
- Comprehensive testing of failure scenarios
- Fallback to individual endpoint calls if needed

### Rollback Plan
- Feature flag to disable aggregated endpoint
- Frontend can fall back to individual backend calls
- Cache can be cleared for troubleshooting

## Testing Strategy

### Unit Tests
- Data aggregation logic with various inclusion parameters
- Error handling for partial backend failures
- Cache key generation and TTL logic
- Response format validation

### Integration Tests
- End-to-end run data aggregation with mock backend
- Concurrent request handling and timeout scenarios
- Cache behavior with Redis integration
- Partial failure scenarios and graceful degradation

### Contract Tests
- Response format validation against frontend expectations
- Data consistency between aggregated and individual calls
- Error response format compatibility

### Performance Tests
- Response time measurement for various run sizes
- Concurrent request handling capacity
- Cache performance and hit rate optimization
- Memory usage with large equity curves and order histories

### Load Tests
- Multiple concurrent run detail requests
- Backend failure scenario handling
- Cache performance under load
- Resource utilization monitoring

---

**Story ID**: S8.4
**Created**: 2025-01-27
**Epic Reference**: [`docs/prd/epic-8-bff-implementation.md`](../prd/epic-8-bff-implementation.md)
**Architecture Reference**: [`docs/architecture/bff-architecture.md`](../architecture/bff-architecture.md)
