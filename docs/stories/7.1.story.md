# Story 7.1 â€” Logging and minimal metrics (operability)
Story ID: S7.1
Epic ID: E7



Status: Ready

User Story
- As an operator,
- I want structured JSON logs and minimal metrics across API and jobs,
- So that I can trace runs, diagnose issues, and observe basic performance.

Context
- Add cross-cutting operability to existing code paths. Keep scope minimal for MVP.


Dependencies
- Depends on: S1.x (skeleton), S4.x (runs/artifacts), S5.x (streaming)
- Blocks: S7.3 (performance validation)

References
- Coding Standards: docs/architecture/coding-standards.md
- Performance Plan: docs/qa/performance-test-plan.md
- Error Codes: docs/api/error-codes.md

Definition of Ready
- Context clarified; dependencies and references listed
- ACs measurable and testable; cite canonical docs
- QA mapping present (see docs/qa/story-to-qa-mapping.md)

Acceptance Criteria
1) All API requests log JSON lines including: `ts, level, msg, request_id, route, method, status, latency_ms` (where applicable)
2) Backtest lifecycle logs include: `run_id, idempotency_key, input_hash, status transitions, duration_ms`
3) Jobs (ingest/derive/backtest) log `symbol, year, sizes_bytes, durations_ms`; errors include codes/messages
4) Minimal metrics available (even via logs): `ingest_ms, derive_ms, backtest_ms, frames_sent, frames_dropped, ws_disconnects`
5) No PII; bind remains 127.0.0.1; logs are parseable JSON without mixed formatting
6) Lint passes; no event-loop blocking added

Dev Notes (sourced from architecture docs)
- Operability & Observability logging fields and minimal metrics [Source: architecture.md#operability--observability]
- NFRs latency and WS jitter budgets (for later validation) [Source: architecture.md#non-functional-requirements-and-performance-budgets]

Technical Specifications
- Backend Python logging: stdlib logging + structlog JSON renderer (fields as above)
- Attach request_id middleware; add run_id/idempotency_key where applicable
- Job logs: use same logger config; include key fields and durations
- Metrics: expose via logs for MVP (counters/timers); optional in-memory counters

Tasks / Subtasks
- Configure logging in backend app startup (JSON, levels, request_id)
- Add logging to services/backtests (create/list/get) and subprocess launcher
- Add logging to jobs/ingest.py, jobs/derive.py, jobs/run_backtest.py (start, end, durations)
- Add counters: frames_sent/dropped and ws_disconnects in streamer/WS adapter
- Run `make lint`; spot-check logs for structure

Testing & Validation
- Exercise typical flows; verify presence of fields and parseability
- Intentionally cause an error; verify error log fields include code/message/run_id

Definition of Done
- Structured logs with key fields across API and jobs; minimal metrics present via logs; no regressions.

