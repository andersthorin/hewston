# Story 7.3 — Performance budgets validation (latency, jitter, storage)
Story ID: S7.3
Epic ID: E7



Status: Ready

User Story
- As an owner-operator,
- I want to validate that MVP meets the stated non-functional performance budgets,
- So that I can trust responsiveness and stability before expanding scope.

Context
- Measure against Architecture NFRs. Produce a short report and recommended tunings if needed.


Dependencies
- Depends on: S7.1 (logging/metrics), S5.x (streaming), S2.x (REST list/get)
- Blocks: N/A

References
- Performance Plan: docs/qa/performance-test-plan.md
- Scripts: scripts/ (to be added by this story)
- Coding Standards: docs/architecture/coding-standards.md

Definition of Ready
- Context clarified; dependencies and references listed
- ACs measurable and testable; cite canonical docs
- QA mapping present (see docs/qa/story-to-qa-mapping.md)

Acceptance Criteria
1) REST latency (local): median ≤ 50 ms; P95 ≤ 200 ms over 200 requests (GET /backtests and GET /backtests/{id} mix)
2) WebSocket playback: jitter median ≤ 30 ms; P95 ≤ 80 ms; effective frame rate ≈30 FPS over at least 60s
3) Storage budgets: derived symbol-year ≤ 250 MB; per-run artifacts ≤ 50 MB (sample AAPL-2023, baseline strategy)
4) Report: markdown summary saved to docs/qa/nfr-validation.md including methods, measurements, and variances (if any) with mitigation plan
5) All measurements reproducible via documented steps and scripts; logs captured

Dev Notes (sourced from architecture docs)
- NFR targets and budgets [Source: architecture.md#non-functional-requirements-and-performance-budgets]
- Operability metrics/logging to aid measurement [Source: architecture.md#operability--observability]

Technical Specifications
- Create lightweight scripts in scripts/ (no external deps if avoidable):
  - scripts/bench_rest.sh: curl loops with timing; compute median/P95 (awk)
  - scripts/bench_ws.js or .ts (optional): simple Node client to measure inter-frame intervals and FPS
  - scripts/measure_sizes.sh: du -sh on derived and per-run artifact dirs
- Document steps in docs/qa/nfr-validation.md (generated by this story)

Tasks / Subtasks
- Author measurement scripts with clear usage/help
- Run measurements on M2-class machine; collect data
- Write docs/qa/nfr-validation.md with results and any proposed tuning
- Add notes if any budgets not met and propose mitigations (decimation tweaks, batching, etc.)

Testing & Validation
- Re-run scripts twice; ensure similar results (± reasonable variance)

Definition of Done
- NFR validation report committed with measurements meeting or explaining variances against targets; scripts runnable locally.

